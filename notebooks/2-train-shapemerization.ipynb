{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18dfa935-c962-4813-a3ab-bc933c8ddbb5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b738ce1-a94b-4d72-a3c9-09ffdfaeb08b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import prody as pd\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scripts import utils, model_utils\n",
    "from scripts.atomic_moments import MultipleAtomicMoments, MOMENT_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2dd364",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.confProDy(verbosity=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32a2a1a-d8b7-49fd-aedf-9778426fdae6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "RADII = [5, 10]\n",
    "KMER_SIZES = [8, 16]\n",
    "ATOMS = [\"calpha\"]\n",
    "\n",
    "POSITIVE_TM_THRESHOLD = 0.8  # only protein pairs with >this TM score considered for positive residue pairs\n",
    "NEGATIVE_TM_THRESHOLD = 0.6  # only protein pairs with <this TM score considered for negative residue pairs\n",
    "\n",
    "POSITIVE_RMSD_THRESHOLD = 2  # only residue pairs with <this weighted shapemer RMSD considered for positive residue pairs\n",
    "NEGATIVE_RMSD_THRESHOLD = 5  # only residue pairs with >this weighted shapemer RMSD considered for negative residue pairs\n",
    "\n",
    "NUM_MOMENTS = MultipleAtomicMoments.from_prody_atomgroup(\"test\", pd.parsePDB(\"5eat\"),\n",
    "                                                         radii=RADII, kmer_sizes=KMER_SIZES,\n",
    "                                                         selection=ATOMS,\n",
    "                                                         moment_types=MOMENT_TYPES).normalized_moments.shape[1]\n",
    "print(NUM_MOMENTS)\n",
    "NUM_BITS = 10\n",
    "NUM_HIDDEN = 512\n",
    "\n",
    "MODEL_NAME = \"model10\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c950e6-be9e-4377-ac4b-be1b605d8144",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Making data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ae02a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = Path(\"data\")\n",
    "pdb_folder = data_folder / \"cath_data\" / \"dompdb\"\n",
    "matrices_folder = data_folder / \"cath_data\" / \"rotation_matrices\"\n",
    "training_data_folder = data_folder / \"training_data\"\n",
    "training_data_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccf1ce4-3348-4a4e-ae18-dbc573e29a35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7865723237064fb294b1c0ebed0746c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "funfam_clusters = {}\n",
    "id_to_funfam_cluster = {}\n",
    "superfamily_clusters = defaultdict(list)\n",
    "id_to_superfamily_cluster = {}\n",
    "with open(data_folder / \"cath_data\" / \"clusters.txt\") as f:\n",
    "    for line in tqdm(f):\n",
    "        match_id, query_ids = line.strip().split(\": \")\n",
    "        query_ids = query_ids.split(\", \")\n",
    "        funfam_clusters[match_id] = query_ids\n",
    "        superfamily_id = match_id.split(\"/FF\")[0]\n",
    "        superfamily_clusters[superfamily_id] += query_ids\n",
    "        for qid in query_ids:\n",
    "            id_to_funfam_cluster[qid] = match_id\n",
    "            id_to_superfamily_cluster[qid] = superfamily_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67518495-7ffc-409e-9e26-628312486276",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_positives_negatives(filename,\n",
    "                            positive_tm_threshold=POSITIVE_TM_THRESHOLD,\n",
    "                            negative_tm_threshold=NEGATIVE_TM_THRESHOLD,\n",
    "                            positive_rmsd_threshold=POSITIVE_RMSD_THRESHOLD,\n",
    "                            negative_rmsd_threshold=NEGATIVE_RMSD_THRESHOLD):\n",
    "    if not (filename.parent / filename.stem).exists():\n",
    "        return []\n",
    "\n",
    "    query_1, query_2 = filename.stem.split(\"_\")\n",
    "    if id_to_funfam_cluster[query_1] == id_to_funfam_cluster[query_2]:\n",
    "        is_positive = True\n",
    "    else:\n",
    "        is_positive = False\n",
    "\n",
    "    min_tmscore = 2\n",
    "    max_tmscore = 0\n",
    "    for key, _ in utils.get_sequences_from_fasta_yield(filename):\n",
    "        if key is None:\n",
    "            return []\n",
    "        tmscore = float(key.split(\"\\t\")[-1].split(\"=\")[-1])\n",
    "        if tmscore < min_tmscore:\n",
    "            min_tmscore = tmscore\n",
    "        if tmscore > max_tmscore:\n",
    "            max_tmscore = tmscore\n",
    "\n",
    "    if is_positive and min_tmscore < positive_tm_threshold:\n",
    "        return []\n",
    "    if not is_positive and max_tmscore > negative_tm_threshold:\n",
    "        return []\n",
    "\n",
    "    matrix = np.zeros((3, 4))\n",
    "    with open(filename.parent / filename.stem) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if 1 < i < 5:\n",
    "                matrix[i - 2] = list(map(float, line.strip().split()[1:]))\n",
    "\n",
    "    with open(pdb_folder / query_1) as f:\n",
    "        pdb_1 = pd.parsePDBStream(f)\n",
    "    with open(pdb_folder / query_2) as f:\n",
    "        pdb_2 = pd.parsePDBStream(f)\n",
    "    transformation = pd.Transformation(matrix[:, 1:], matrix[:, 0])\n",
    "    pdb_1 = pd.applyTransformation(transformation, pdb_1)\n",
    "    aln = utils.get_sequences_from_fasta(filename)\n",
    "    aln = {k.split(\"\\t\")[0].split(\":\")[0].split(\"/\")[-1]: aln[k] for k in aln}\n",
    "    aln_np = utils.alignment_to_numpy(aln)\n",
    "\n",
    "    calpha_1 = pdb_1.select(\"calpha\")\n",
    "    coords_1 = calpha_1.getCoords()\n",
    "    moments_1 = MultipleAtomicMoments.from_prody_atomgroup(query_1, pdb_1, radii=RADII, kmer_sizes=KMER_SIZES,\n",
    "                                                           selection=ATOMS, moment_types=MOMENT_TYPES)\n",
    "    neighbors_1, vector_1 = moments_1.get_neighbors(), moments_1.normalized_moments\n",
    "\n",
    "    calpha_2 = pdb_2.select(\"calpha\")\n",
    "    coords_2 = calpha_2.getCoords()\n",
    "    moments_2 = MultipleAtomicMoments.from_prody_atomgroup(query_2, pdb_2, radii=RADII, kmer_sizes=KMER_SIZES,\n",
    "                                                           selection=ATOMS, moment_types=MOMENT_TYPES)\n",
    "    vector_2 = moments_2.normalized_moments\n",
    "    ndim = vector_1.shape[1]\n",
    "\n",
    "    data_points = []\n",
    "    mapping = np.zeros(coords_1.shape[0], dtype=int)\n",
    "    mapping[:] = -1\n",
    "    for i, x in enumerate(aln_np[query_1]):\n",
    "        if x == -1:\n",
    "            continue\n",
    "        mapping[x] = aln_np[query_2][i]\n",
    "\n",
    "    for x in range(len(aln_np[query_1])):\n",
    "        aligned = True\n",
    "        if is_positive:\n",
    "            a1, a2 = aln_np[query_1][x], aln_np[query_2][x]\n",
    "        else:\n",
    "            a1, a2 = aln_np[query_1][x], aln_np[query_2][x]\n",
    "            if a2 == -1:\n",
    "                aligned = False\n",
    "                a2 = aln_np[query_2][\n",
    "                    np.random.choice([x1 for x1 in range(len(aln_np[query_2])) if aln_np[query_2][x1] != -1])]\n",
    "\n",
    "        if a1 != -1 and a2 != -1:\n",
    "            rmsd = utils.get_rmsd_neighbors(coords_1, coords_2, a1, np.array(list(neighbors_1[a1])), mapping)\n",
    "            if (is_positive and rmsd < positive_rmsd_threshold) or (not is_positive and rmsd > negative_rmsd_threshold):\n",
    "                data_point = {\"target_1\": query_1, \"target_2\": query_2,\n",
    "                              \"index_1\": a1, \"index_2\": a2, \"rmsd\": rmsd,\n",
    "                              \"ndim\": ndim, \"aligned\": aligned,\n",
    "                              \"label\": int(is_positive)}\n",
    "                for n in range(ndim):\n",
    "                    data_point[f\"d1_{n}\"] = vector_1[a1][n]\n",
    "                    data_point[f\"d2_{n}\"] = vector_2[a2][n]\n",
    "                data_points.append(data_point)\n",
    "    return data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0919585-7730-408c-a9c0-6347778b8d74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_files = sum(1 for _ in matrices_folder.glob(\"*.fasta\"))\n",
    "with open(training_data_folder / \"data.txt\", \"w\") as f:\n",
    "    header = [\"target_1\", \"target_2\", \"index_1\", \"index_2\",\n",
    "              \"rmsd\", \"ndim\", \"aligned\", \"label\"] + [f\"d1_{n}\" for n in range(NUM_MOMENTS)] + [f\"d2_{n}\" for n in\n",
    "                                                                                               range(NUM_MOMENTS)]\n",
    "    f.write(\"\\t\".join(header) + \"\\n\")\n",
    "    n_pos = 0\n",
    "    n_neg = 0\n",
    "    for i, filename in tqdm(enumerate(matrices_folder.glob(\"*.fasta\")), total=num_files):\n",
    "        if i % 500 == 0:\n",
    "            print(i, n_pos, n_neg)\n",
    "        data_points = get_positives_negatives(filename)\n",
    "        for data_point in data_points:\n",
    "            if data_point[\"label\"]:\n",
    "                n_pos += 1\n",
    "            else:\n",
    "                n_neg += 1\n",
    "            f.write(\"\\t\".join(str(data_point[c]) for c in header) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a912a-7902-469e-8fb0-8be723b7876c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d7731-98b5-451d-81eb-ac9ce1d06154",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pairs_a = []\n",
    "pairs_b = []\n",
    "ys = []\n",
    "rmsds = []\n",
    "aligned = []\n",
    "limit = 5_000_000\n",
    "with open(training_data_folder / \"data.txt\", \"r\") as f:\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        if limit == 0:\n",
    "            break\n",
    "        if i == 0:\n",
    "            continue\n",
    "        line = line.split(\"\\t\")\n",
    "        try:\n",
    "            pairs_a.append(np.array([float(x) for x in line[8: 8 + NUM_MOMENTS]]))\n",
    "            pairs_b.append(np.array([float(x) for x in line[8 + NUM_MOMENTS:]]))\n",
    "            assert len(pairs_a[-1]) == len(pairs_b[-1])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        rmsds.append(float(line[4]))\n",
    "        aligned.append(True if line[6] == \"True\" else False)\n",
    "        ys.append(int(line[7]))\n",
    "        limit -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf9be42-4efc-4b11-a46c-ab4408149ea8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pairs_a = np.vstack(pairs_a)\n",
    "pairs_b = np.vstack(pairs_b)\n",
    "ys = np.array(ys)\n",
    "rmsds = np.array(rmsds)\n",
    "aligned = np.array(aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d74c80d-27a1-49d6-95a0-e9efafe08abb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2252140, 1710394, 2044320, 1158629, 3118099, 2986818,  275000,\n",
       "       2123771,  319800, 2182016])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(rmsds))\n",
    "np.random.shuffle(idx)\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23ee1e5-aead-46a2-bcc0-361320271e5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2030781,), (1463426,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_a = pairs_a[idx]\n",
    "pairs_b = pairs_b[idx]\n",
    "pairs_a = np.nan_to_num(pairs_a)\n",
    "pairs_b = np.nan_to_num(pairs_b)\n",
    "ys = ys[idx]\n",
    "rmsds = rmsds[idx]\n",
    "aligned = aligned[idx]\n",
    "aligned[aligned == 1].shape, aligned[aligned == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38da2f5-a6ec-434d-90e3-e7e9ed8af07b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_ids_neg = np.random.choice(np.where((aligned == 1) & (ys == 0))[0], 512)\n",
    "test_ids_pos = np.random.choice(np.where((ys == 1))[0], 512)\n",
    "test_ids = np.concatenate((test_ids_neg, test_ids_pos))\n",
    "test_ban = set(list(test_ids))\n",
    "train_ids = np.array([x for x in range(len(pairs_a)) if x not in test_ban])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac69a3-ae06-423d-8f12-2334c9075f0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pairs_a = pairs_a[train_ids]\n",
    "train_pairs_b = pairs_b[train_ids]\n",
    "train_ys = ys[train_ids]\n",
    "train_rmsds = rmsds[train_ids]\n",
    "train_aligned = aligned[train_ids]\n",
    "\n",
    "test_pairs_a = pairs_a[test_ids]\n",
    "test_pairs_b = pairs_b[test_ids]\n",
    "test_ys = ys[test_ids]\n",
    "test_rmsds = rmsds[test_ids]\n",
    "test_aligned = aligned[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a90060-2e38-4802-af15-52b671f293fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batches = [(torch.tensor(train_pairs_a[i: i + 2048 * 2].astype(np.float32)).cuda(),\n",
    "            torch.tensor(train_pairs_b[i: i + 2048 * 2].astype(np.float32)).cuda(),\n",
    "            torch.tensor(train_ys[i: i + 2048 * 2].astype(np.float32)).cuda()) for i in\n",
    "           range(0, len(train_pairs_b), 2048 * 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fca61f-d5ce-4b4f-8549-2c52453a38bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_rmsds = [train_rmsds[i: i + 2048 * 2] for i in range(0, len(train_pairs_b), 2048 * 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27cad77-36a6-4eaf-ab60-b14238ae896a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_batch = (torch.tensor(test_pairs_a.astype(np.float32)).cuda(),\n",
    "              torch.tensor(test_pairs_b.astype(np.float32)).cuda(),\n",
    "              torch.tensor(test_ys.astype(np.float32)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36740aa7-541f-4ef1-ba4a-c1c23a09d853",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "model = model_utils.MomentLearn(NUM_MOMENTS, NUM_HIDDEN, NUM_BITS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "347e013d-1e5d-4f46-9c78-f9fed6c31fa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14931ce-9afd-4cd1-a850-76f945f482f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_losses = []\n",
    "for e in range(epoch):\n",
    "    for x, dist, y in tqdm(batches):\n",
    "        x, dist, y = model(x, dist, y)\n",
    "        loss = model_utils.loss_func(x, dist, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        current_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "    if e % 5 == 0:\n",
    "        model.eval()\n",
    "        test_x, test_dist, test_y = test_batch\n",
    "        test_x_i, test_dist_i, test_y_i = model(test_x, test_dist, test_y)\n",
    "        loss = model_utils.loss_func(test_x_i, test_dist_i, test_y_i)\n",
    "        test_x_i, test_dist_i, test_y_i = test_x_i.cpu().detach().numpy(), test_dist_i.cpu().detach().numpy(), test_y_i.cpu().detach().numpy()\n",
    "        train_x_i, train_dist_i, train_y_i = x.cpu().detach().numpy(), dist.cpu().detach().numpy(), y.cpu().detach().numpy()\n",
    "        train_distances = np.abs(train_x_i - train_dist_i).mean(1)\n",
    "        distances = np.abs(test_x_i - test_dist_i).mean(1)\n",
    "        plt.hexbin(test_rmsds, distances, cmap=\"RdBu\")\n",
    "        plt.show()\n",
    "        print()\n",
    "        print(\"train loss:\", np.mean(current_losses))\n",
    "        print(\"test loss:\", loss.item())\n",
    "        metrics.PrecisionRecallDisplay.from_predictions(test_y_i.astype(int), -distances)\n",
    "        plt.show()\n",
    "        current_losses = []\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f26148a-b6ce-4ef8-adf3-77af7aa0678f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MomentLearn(\n",
       "  (linear_segment): Sequential(\n",
       "    (0): Linear(in_features=68, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, f\"{MODEL_NAME}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ab6a161ba03c21d4642db29cdaabcfb98eddbe4c95ae95609ca0691105e488b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}